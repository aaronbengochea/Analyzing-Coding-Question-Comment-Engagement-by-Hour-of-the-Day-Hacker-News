{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the csv file by using the python csv module to open and read the file. \n",
    "We then display then display column names and the top 5 rows of data in order to get a better understanding of the data we are dealing with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 6549: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\abeng\\Desktop\\Project - Hacker News\\Comment Engagement Analysis.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/abeng/Desktop/Project%20-%20Hacker%20News/Comment%20Engagement%20Analysis.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m csvreader \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mreader(file)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/abeng/Desktop/Project%20-%20Hacker%20News/Comment%20Engagement%20Analysis.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m hn \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/abeng/Desktop/Project%20-%20Hacker%20News/Comment%20Engagement%20Analysis.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m csvreader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/abeng/Desktop/Project%20-%20Hacker%20News/Comment%20Engagement%20Analysis.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     hn\u001b[39m.\u001b[39mappend(row)\n",
      "File \u001b[1;32mc:\\Users\\abeng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39;49mcharmap_decode(\u001b[39minput\u001b[39;49m,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,decoding_table)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x81 in position 6549: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime as dt\n",
    "\n",
    "file = open('hacker_news.csv')\n",
    "csvreader = csv.reader(file)\n",
    "\n",
    "hn = []\n",
    "for row in csvreader:\n",
    "    hn.append(row)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12579008',\n",
       "  'You have two days to comment if you want stem cells to be classified as your own',\n",
       "  'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018',\n",
       "  '1',\n",
       "  '0',\n",
       "  'altstar',\n",
       "  '9/26/2016 3:26'],\n",
       " ['12579005',\n",
       "  'SQLAR  the SQLite Archiver',\n",
       "  'https://www.sqlite.org/sqlar/doc/trunk/README.md',\n",
       "  '1',\n",
       "  '0',\n",
       "  'blacksqr',\n",
       "  '9/26/2016 3:24'],\n",
       " ['12578997',\n",
       "  'What if we just printed a flatscreen television on the side of our boxes?',\n",
       "  'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43',\n",
       "  '1',\n",
       "  '0',\n",
       "  'pavel_lishin',\n",
       "  '9/26/2016 3:19'],\n",
       " ['12578989',\n",
       "  'algorithmic music',\n",
       "  'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext',\n",
       "  '1',\n",
       "  '0',\n",
       "  'poindontcare',\n",
       "  '9/26/2016 3:16']]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then assign the list containing the column names to a variable named headers. We remove the first list from hn which we just assigned to headers. We then assign hn back to itself excluding the first list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12579008',\n",
       "  'You have two days to comment if you want stem cells to be classified as your own',\n",
       "  'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018',\n",
       "  '1',\n",
       "  '0',\n",
       "  'altstar',\n",
       "  '9/26/2016 3:26'],\n",
       " ['12579005',\n",
       "  'SQLAR  the SQLite Archiver',\n",
       "  'https://www.sqlite.org/sqlar/doc/trunk/README.md',\n",
       "  '1',\n",
       "  '0',\n",
       "  'blacksqr',\n",
       "  '9/26/2016 3:24'],\n",
       " ['12578997',\n",
       "  'What if we just printed a flatscreen television on the side of our boxes?',\n",
       "  'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43',\n",
       "  '1',\n",
       "  '0',\n",
       "  'pavel_lishin',\n",
       "  '9/26/2016 3:19'],\n",
       " ['12578989',\n",
       "  'algorithmic music',\n",
       "  'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext',\n",
       "  '1',\n",
       "  '0',\n",
       "  'poindontcare',\n",
       "  '9/26/2016 3:16'],\n",
       " ['12578979',\n",
       "  'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake',\n",
       "  'https://www.talend.com/blog/2016/05/12/talend-and-Ã‚Â“the-data-vaultÃ‚Â”',\n",
       "  '1',\n",
       "  '0',\n",
       "  'markgainor1',\n",
       "  '9/26/2016 3:14']]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn = hn[1:]\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now initate 3 lists, we then itereate through each list within hn in order to seperate each list by title. We create 3 buckets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in hn:\n",
    "    title = row[1]\n",
    "    \n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "    \n",
    "                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5884\n",
      "6109\n",
      "168842\n"
     ]
    }
   ],
   "source": [
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate through our ask posts bucket list to find the total number of comments within posts titled ask hn, we also compute the average posts per post within the ask hn bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ask_comments = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ask_comments = round(total_ask_comments / len(ask_posts),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.25"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_ask_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66223"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_ask_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate through our show posts bucket list to find the total number of comments within posts titled show hn, we also compute the average posts per post within the show hn bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_show_comments = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_show_comments = round(total_show_comments / len(show_posts),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.96"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_show_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30287"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_show_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make 3 key observations from the information we have gathered above:\n",
    "1) There are more ask posts (1744) then there are shows posts (1,162)\n",
    "\n",
    "2) Ask posts recieved a total of 24,483 comments while Show posts only recieved 11,988 comments.\n",
    "\n",
    "3) Ask posts tend to garner more engagement when compared to show posts. Ask posts generate 14 commments per post  while Show posts only generate 10 on average. There are also ~600 more ask posts then there are show posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now focus in on ask hn since we found that is where most of the significance/relevencance is. We iterate through the ask posts in order to determine how many posts are made by hour of the day while also determining how many comments are made by hour. Understanding these two metrics will give us better insite as to when users are most active and the times which you are most likely to get answers/feedback to your questoin posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "\n",
    "for row in ask_posts:\n",
    "    time = row[6]\n",
    "    comments = int(row[4])\n",
    "    combo = [time,comments]\n",
    "    result_list.append(combo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['9/26/2016 2:53', 7],\n",
       " ['9/26/2016 1:17', 3],\n",
       " ['9/25/2016 22:57', 0],\n",
       " ['9/25/2016 22:48', 3],\n",
       " ['9/25/2016 21:50', 2]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in result_list:\n",
    "    hour = row[0]\n",
    "    comments = row[1]\n",
    "    time = dt.datetime.strptime(hour, '%m/%d/%Y %H:%M')\n",
    "    \n",
    "    if time.hour not in counts_by_hour:\n",
    "        counts_by_hour[time.hour] = 1\n",
    "        comments_by_hour[time.hour] = comments\n",
    "        \n",
    "    else:\n",
    "        counts_by_hour[time.hour] += 1\n",
    "        comments_by_hour[time.hour] += comments\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 180),\n",
       " (1, 185),\n",
       " (2, 167),\n",
       " (3, 170),\n",
       " (4, 148),\n",
       " (5, 141),\n",
       " (6, 150),\n",
       " (7, 159),\n",
       " (8, 178),\n",
       " (9, 144),\n",
       " (10, 184),\n",
       " (11, 195),\n",
       " (12, 229),\n",
       " (13, 303),\n",
       " (14, 336),\n",
       " (15, 417),\n",
       " (16, 354),\n",
       " (17, 385),\n",
       " (18, 406),\n",
       " (19, 348),\n",
       " (20, 305),\n",
       " (21, 348),\n",
       " (22, 243),\n",
       " (23, 209)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_by_hour = sorted(counts_by_hour.items(), key=lambda x: int(x[0]))\n",
    "counts_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1443),\n",
       " (1, 1139),\n",
       " (2, 2074),\n",
       " (3, 1549),\n",
       " (4, 1597),\n",
       " (5, 933),\n",
       " (6, 885),\n",
       " (7, 1216),\n",
       " (8, 1855),\n",
       " (9, 1019),\n",
       " (10, 2268),\n",
       " (11, 2003),\n",
       " (12, 3301),\n",
       " (13, 5579),\n",
       " (14, 3686),\n",
       " (15, 12543),\n",
       " (16, 3262),\n",
       " (17, 4278),\n",
       " (18, 3290),\n",
       " (19, 2468),\n",
       " (20, 3392),\n",
       " (21, 2687),\n",
       " (22, 2340),\n",
       " (23, 1416)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_by_hour = sorted(comments_by_hour.items(), key=lambda x: int(x[0]))\n",
    "comments_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now work on finding the average number of comments on any given post at any given 1 hour time interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 8.016666666666667],\n",
       " [1, 6.1567567567567565],\n",
       " [2, 12.419161676646707],\n",
       " [3, 9.111764705882353],\n",
       " [4, 10.79054054054054],\n",
       " [5, 6.617021276595745],\n",
       " [6, 5.9],\n",
       " [7, 7.647798742138365],\n",
       " [8, 10.42134831460674],\n",
       " [9, 7.076388888888889],\n",
       " [10, 12.326086956521738],\n",
       " [11, 10.271794871794873],\n",
       " [12, 14.414847161572052],\n",
       " [13, 18.41254125412541],\n",
       " [14, 10.970238095238095],\n",
       " [15, 30.07913669064748],\n",
       " [16, 9.214689265536723],\n",
       " [17, 11.111688311688312],\n",
       " [18, 8.10344827586207],\n",
       " [19, 7.091954022988506],\n",
       " [20, 11.121311475409836],\n",
       " [21, 7.721264367816092],\n",
       " [22, 9.62962962962963],\n",
       " [23, 6.77511961722488]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for row in counts_by_hour:\n",
    "    average = (comments_by_hour[row[0]][1] / counts_by_hour[row[0]][1])\n",
    "    avg_by_hour.append([row[0],average])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15, 30.07913669064748],\n",
       " [13, 18.41254125412541],\n",
       " [12, 14.414847161572052],\n",
       " [2, 12.419161676646707],\n",
       " [10, 12.326086956521738],\n",
       " [20, 11.121311475409836],\n",
       " [17, 11.111688311688312],\n",
       " [14, 10.970238095238095],\n",
       " [4, 10.79054054054054],\n",
       " [8, 10.42134831460674],\n",
       " [11, 10.271794871794873],\n",
       " [22, 9.62962962962963],\n",
       " [16, 9.214689265536723],\n",
       " [3, 9.111764705882353],\n",
       " [18, 8.10344827586207],\n",
       " [0, 8.016666666666667],\n",
       " [21, 7.721264367816092],\n",
       " [7, 7.647798742138365],\n",
       " [19, 7.091954022988506],\n",
       " [9, 7.076388888888889],\n",
       " [23, 6.77511961722488],\n",
       " [5, 6.617021276595745],\n",
       " [1, 6.1567567567567565],\n",
       " [6, 5.9]]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = sorted(avg_by_hour, key = lambda x: x[1],reverse = True)\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the best times to post are ~20-40 minutes before the hours of 3pm, 2am, 8pm, 4pm and 9pm, respectively. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Post Comment Engagement\n",
      "\n",
      "15:00: 30.08 average comments per post\n",
      "13:00: 18.41 average comments per post\n",
      "12:00: 14.41 average comments per post\n",
      "02:00: 12.42 average comments per post\n",
      "10:00: 12.33 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print('Top 5 Hours for Ask Post Comment Engagement\\n')\n",
    "for row in avg_by_hour[:5]:\n",
    "    time = dt.datetime.strptime(str(row[0]),'%H')\n",
    "    time = time.strftime('%H:00')\n",
    "    comments = '{:.2f}'.format(row[1])\n",
    "    \n",
    "    print(f\"{time}: {comments} average comments per post\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f8d3cce99c871ce0e0a87960ec08013533f4babee7be0009bb2842dcda8da03b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
